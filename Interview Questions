What is jenkins remote access API?
  - install the plugin called "Build authorization token trigger"
  - on jenkins at the build triggers enable the option "build this job remotely"
  - demo url "http://localhost:8080/view/CodeBook/job/Job1/build?token=12345"
  
what are the uses of parameters and how to do build parameterized ?
  - A build parameter allows us to pass data into our Jenkins jobs.
  - Using build parameters, we can pass any data we want: git branch name, secret credentials, hostnames and ports, and so on.
  - Any Jenkins job or pipeline can be parameterized. All we need to do is check the box on the General settings tab, “This project is parameterized”.
  Types of parameters:- Boolean parameter, choice parameter, credentials parameter, file parameter, Git parameter.
  
 what are the environment variables in jenkins?
  - Environment variables are predetermined values, Environment variables are global key-value pairs Jenkins can access and inject into a project. 
  - Use Jenkins environment variables to avoid having to code the same values for each project
  
what is git cherry pick command ?
  - Cherry-picking in Git stands for applying some commit from one branch into another branch.
  - In case you made a mistake and committed a change into the wrong branch, but do not want to merge the whole branch. 
  - You can revert the commit and apply it on another branch.
  - Git cherry-pick is helpful to apply the changes that are accidentally made in the wrong branch. 
  - To make all the changes of the new branch into the master branch, we will use the git pull, but for this particular commit, we will use git cherry-pick command. 
  - $  git cherry-pick <commit id>  
  
How to check the git commit id's ?
  $ git log
  
what is bare metal?
 - Bare metal is a computer system without a base operating system (OS) or installed applications.
 
what is Hypervisor ?
  - A hypervisor is a form of virtualization software used in Cloud hosting to divide and allocate the resources on various pieces of hardware.
  - The program which provides partitioning, isolation, or abstraction is called a virtualization hypervisor.
  - The hypervisor is a hardware virtualization technique that allows multiple guest operating systems (OS) to run on a single host system at the same time.
  - The hypervisor runs directly on the underlying host system. 
  
what is the difference between docker and virtual machine ?
 - virtual machine:- 
     - infrastructure -> Host OS -> Hypervisor -> Guest OS on top of this application will be istalled.
     - Allows multiple virtual machines and applications to run on the same physical machine.
     - Host OS can be different from guest OS.
     
 - Docker:- 
     - infrastructure -> Host OS -> Docker daemon -> application
     - The OS is abstracted via containers rather than the hardware. 
     - With the use of containers, a developer can package up a program with all of its constituent elements, 
       including libraries and other dependencies, and deliver it as a single package. 
       
       
 what is git runner ?
   - GitHub offers hosted virtual machines to run workflows.
   - The virtual machine contains an environment of tools, packages, and settings available for GitHub Actions to use.
   - For example, a runner can clone your repository locally, install testing software, and then run commands that evaluate your code.
   - GitHub provides runners that you can use to run your jobs, or you can host your own runners.
   - Each GitHub-hosted runner is a new virtual machine (VM) hosted by GitHub with the runner application,
     and other tools preinstalled, and is available with Ubuntu Linux, Windows, or macOS operating systems.
   - When the job begins, GitHub automatically provisions a new VM for that job. All steps in the job execute on the VM, 
     allowing the steps in that job to share information using the runner's filesystem.
     
 What is S3 bucket versioning and how can you demonstrate this ?
   :- click on the bucket -> properties -> bucket versioning enable -> enable versioning
   :- Suppose you have hosted static website with the image, after that you have added new image then the old image is not going to replace
      it is just going to create the new version of an object
   :- once you hide versions and delete the image, i won't going to be deleted it's just going to mark as delete marker, and image will not be available.
   :- once you show the versions, it will show delete marker and image versions will be available
   :- if you want rollback to previous versions, you can click on show versions and delete the latest version.
 2nd interview
 
  1. Explain about S3 lifecycle and how can you move from one storage class to another?
     - click on the bucket - management -> create lifecycle rule -> select the option ( This rule applies to all objects in the bucket )
     - To filter a rule by object size, you can check Specify minimum object size, Specify maximum object size, or both options
     - Under Lifecycle rule actions, choose the actions that you want your lifecycle rule to perform:
        Transition current versions of objects between storage classes
        Transition previous versions of objects between storage classes
        Expire current versions of objects 
         - This configuration allows users to automatically expire the current version of the Amazon S3 objects stored 
           within the bucket after a specified number of days
         - for version eabled buckets, amazon s3 adds a delete marker as current version of an object will be retained as previous version.
           for non current version S3 will premanently removes the object. 
       Permanently delete previous versions of objects
       Storage classes
        Standard-IA
        Intelligent-Tiering
        One Zone-IA
        S3 Glacier Flexible Retrieval
        Glacier Deep Archive
        Add transition to and select the storage class and Days after object creation, enter the number of days after creation to transition the object
        
  2. How can you access the S3 bucket within the VPC?
      Create one public server and private server attach S3 roles to both of the server, after that go to the VPC endpoints there you select
      the S3 gateway an create it, after you creating that entrypoint will be attached to routing table, then you will be able to access to the
      S3 bucket through private server.
  
  3. we have multiple users only one person can access to S3 bucket, how can you do that?
  
  4. explin about what is the difference between NAT GW and Internet GW and how can you configure them?
     If any private server wants to communicate with the internet, then we have to create NAT gateway have to communicate
     with the internet through NAT gateway.
     create NAT gateway on public subnet and allocate the elastic IP. in in routing table, click routers and add that NGW
     
     we can create an internet gateway and attach it to the VPC and in routing table, click routers and add that IGW.
     Internet is used to comminate with the network for public servers.
     
  5. How the frontend web server can communicate with database server?
  
  6. How the 2 VPCs can communicate each other from 2 different accounts?
  
  7. Whenever any instance state gets changed we need get notified how can you configure that?
  8. How can you access RDS instance through EC2 instance and fetch the information which is stored in RDS?
     first you need to install mysql client on linux machine
     $ sudo yum install mysql 
     allow the 3306 port number on RDS SG and Instance SG
     $ mysql -h endpoint -P port -u masteruser -p 
     
  9. Explain about API Gateway how did you use in your project?
  
  10. what are the limitations of lambda and explain about lambda?
      The disk space (ephemeral) is limited to 512 MB.
      The default deployment package size is 50 MB.
      The memory range is from 128 to 3008 MB.
      The maximum execution timeout for a function is 15 minutes*
      Request and response (synchronous calls) body payload size can be up to to 6 MB.
      Event request (asynchronous calls) body can be up to 128 KB.
      
  11. what are the DNS records ?
       A – maps a hostname to IPv4
       AAAA – maps a hostname to IPv6
       CNAME – maps a hostname to another hostname
       
  12. what is the difference between ALB and NLB?
      <== Application Load Balancer ==>
    • Application load balancers is Layer 7 (HTTP)
    • Load balancing to multiple HTTP applications across machines 
      (target groups)
    • Routing based on path in URL (example.com/users & example.com/posts)
    • Routing based on hostname in URL (one.example.com & other.example.com)
    • ALB are a great fit for micro services & container-based application 
      (example: Docker & Amazon ECS)
    • ALB can route to multiple target groups
    • Health checks are at the target group level
    
 <= Network Load Balancer ==>
    • Network load balancers (Layer 4)
    • Forward TCP & UDP traffic to your instances
    • Handle millions of request per seconds
    • NLB are used for extreme performance, TCP or UDP traffic
    
  13. what could be the reasons of not able to SSH into EC2 instance?
       1. SSH 22 port might not be allowed in security groups
       2. public ip not assigned to that instance
       3. public subnets not been associated with the routing table.
  
  14. I have one server on production env, i have lost the pem.key so how can i login to that instance?
      take the snapshot of the EBS volume, and create volume through snapshot and take snapshot of the AMI,
      whille creating new instance, creat through AMI that we took snapshot from existing VM and attach volume the new instance.
      
  15. what are the difference ways to login to instance apart from SSH?
      SSH into the server and SSH key based authentication.
      
  16. which file will be having all the user information ?
       /etc/passwd ( usernames, encrypted passwords, user id, users group id, the /home directory of the user, users login shell )
       
  17. which file you need to check that how may users have access to the servers?
      
  18. what proc dir will be containing?
      - It contains useful information about the processes that are currently running, it is regarded as control and information center for kernel.
      - ls -ltr /proc/7494
      - Now check the highlighted process with PID=7494, you can check that there is entry for this process in /proc file system.
      - /proc/PID/stat -> Process status
      - /proc/PID/statm -> Process memory status information.
      - /proc/PID/mem	 -> Memory held by this process.
  
  19. am on the the root user and i need to do some tasks with the particular user, how can i do that?
      sudo command -> Run command as root.
      sudo -u root command -> Run command as root.
      sudo -u user command -> Run command as user.
      sudo su -> Switch to the superuser account.
      sudo su -  -> Switch to the superuser account with root's environment.
      sudo su - username -> Switch to the username's account with the username's environment.
      sudo -s -> Start a shell as root
      sudo -u root -s -> Same as above.
      sudo -u user -s -> Start a shell as user.
      
  20. explain about the terraform modules ?
      
  21. you have written terraform script to provision s3 bucket and ec2 instance and subnets, i need to create only ec2 instance how can i do that?
      call the terraform ec2 modue in main.tf file.
      
  22. explain about META arguements in terraform?
  
  23. you have provision the 5 instance and only 1 instance i need to destroy how can i do that?
        $ terraform state list
        $ terraform destroy -target RESOURCE_TYPE.NAME
        $ terraform destroy -target RESOURCE_TYPE.NAME -target RESOURCE_TYPE2.NAME
      How to delete all resources except one?
        terraform state rm <resource_to_be_deleted> 
        
  24. How can you attach role to the existing ec2 instance.
      From the Actions menu, choose Instance Settings → Attach/Replace IAM role.
      
  25. you have written code for the ec2 instance in different file and how can you define that in main.tf file?
  
      module "ec2-instance_example_complete" {
  source  = "terraform-aws-modules/ec2"
  version = "4.3.0"
}
  
  26. How can you store the secrets in terraform?
      
  
  27. There is a file only you can modify that file linux, how can you do that?
      change the ownership of the file
      $ sudo chown someuser:selectgroup /the/file 
      
  28. explain about git rebase?
      - Rebasing is the process of moving or combining a sequence of commits to a new base commit.
      - The primary reason for rebasing is to maintain a linear project history.  
  
  29. i have made the changes on one branch later i got to know i have done the changes on wrong branch, how can i made changes on new branch?
      if you have already commited then hit the command to reset 
      undo and commit to new branch
      $ git reset HEAD~1
      Move Commits to the Other Branch
      $ git log
      $ git reset --hard HEAD~1
      $ git checkout -b newbranch
      $ git reset --hard < commit_id >
      if you have not commited to and move the changes to other baranch
      $ git stash
      $ git checkout new_branch
      $ git stash pop   
      $ git rebase -i HEAD~5 -> sqush commits into one
      $ git reset --hard HEAD~1 -> to delete the commit
      
  30. what is container orchestration ?
      Container orchestration automates the deployment, management, scaling, and networking of containers.
      
  31. how the two containers will communicate each other and how can you ping them from one container to another container?
      create the docker container in the same network.
      $ docker run -d --name container1 -p 8001:80 nginx
      $ docker run -d --name container2 -p 8002:80 nginx
      $ docker network create mynetwork
      $ docker network connect mynetwork contaier1
      $ docker network connect mynetwork conntainer2
      $ docker network inspect myNetwork
      $ docker exec -ti web1 ping web2
  
  33. what are the networks are available on docker and how can you differentiate them?
      - Dockerhost will be having different subnet and container will be having differenet subnet, whenever you create a container
        a bridge network will automatically create it makes the communication between dockerhost and container, bridge network can be called as
        docker0.
      Host network:- when you create a container it will directly bind to the host network like, whatever dockerhost is having ip address same rang
        of ip address range will get to container. whoever access to host can have access to container as well. this is having some security concerns.
      
  34. How can you upgrade latest image to the container?
      pull the latest image, create container out of it and remove the old pod
      
  35. what is the difference between kubernetes and docker?
      docker is the containarized platform, kubernetes is the container orchestration
      
  36. how can you do autoscaling in kubernetes?
      HorizontalPodAutoscaler controls the scale of a Deployment and its ReplicaSet
      $ kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
      
  37. what are the kubernetes services?
      ClusterIP. Exposes a service which is only accessible from within the cluster.
      NodePort. Exposes a service via a static port on each node’s IP.
      LoadBalancer. Exposes the service via the cloud provider’s load balancer.
      
  38. how the communication happen from one pod to another pod in kubernetes
      every pod will be having clusterIP, through clusterIP pods communication will happend
  39. How can you differentiate the containers in pod and how the containers communicate through one container to another container
      pod is a isolated network namespace, container can talk via localhost and port
  40. How can you secure your kubernetes application ?
      RBAC and 
  41. what is kube proxy and kubelet?
      kubelet - An agent that runs on each node in the cluster. It makes sure that containers are running in a Pod.
  
  kube-proxy - kube-proxy is a network proxy that runs on each node in your cluster, kube-proxy maintains network rules on nodes. 
    These network rules allow network communication to your Pods
    
  42. How the traffic will go to the pod, tell me the flow and explain?
      traffic will hit to the ingress, and service called load balancer, goes to the Pod.
      
  43. what is container resource monitoring?
      Container monitoring is the activity of continuously collecting metrics and tracking the health of containerized applications and microservices environments, 
      in order to improve their health and performance and ensure they are operating smoothly. 
  44. How can you optimize the kubernetes  
  
3rd interview ( KANINI )
1. explain about docker architecture ?
   - Docker uses a client-server architecture. The Docker client talks to the Docker daemon, 
   - which does the heavy lifting of building, running, and distributing your Docker containers.
   - The Docker client and daemon can run on the same system, or you can connect a Docker client to a remote Docker daemon.
   The Docker daemon
   - The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. 
   The Docker client
   - The Docker client (docker) is the primary way that many Docker users interact with Docker. 
   - When you use commands such as docker run, the client sends these commands to dockerd, which carries them out.
   - The docker command uses the Docker API. The Docker client can communicate with more than one daemon.
   
2. explain about docker daemon
   - The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes.
   
3. explain about S3 lifecycle policy?
   - click on the bucket - management -> create lifecycle rule -> select the option ( This rule applies to all objects in the bucket )
     - To filter a rule by object size, you can check Specify minimum object size, Specify maximum object size, or both options
     - Under Lifecycle rule actions, choose the actions that you want your lifecycle rule to perform:
        Transition current versions of objects between storage classes
        Transition previous versions of objects between storage classes
        Expire current versions of objects 
         - This configuration allows users to automatically expire the current version of the Amazon S3 objects stored 
           within the bucket after a specified number of days
         - for version eabled buckets, amazon s3 adds a delete marker as current version of an object will be retained as previous version.
           for non current version S3 will premanently removes the object. 
       Permanently delete previous versions of objects
       Storage classes
        Standard-IA
        Intelligent-Tiering
        One Zone-IA
        S3 Glacier Flexible Retrieval
        Glacier Deep Archive
        Add transition to and select the storage class and Days after object creation, enter the number of days after creation to transition the object
        
4. what is VPC peering and how can you configure that?
    
5. How many S3 buckets can be created per one account?
   100 S3 buckets
   
6. what is blue green deployment strategy ?
   - Blue-green deployment is a technique that reduces downtime and risk by running two identical production environments called Blue and Green.
   - At any time, only one of the environments is live, with the live environment serving all production traffic. 
     For this example, Blue is currently live and Green is idle
   - As you prepare a new version of your software, deployment and the final stage of testing takes place in the environment that is not live:
   - in this example, Green. Once you have deployed and fully tested the software in Green, you switch the router so all incoming requests 
     now go to Green instead of Blue. Green is now live, and Blue is idle.
   - This technique can eliminate downtime due to app deployment. In addition, blue-green deployment reduces risk:
   - if something unexpected happens with your new version on Green, you can immediately roll back to the last version by switching back to Blue.

7. what is stateless and statefull pods in kubernetes?
   which pod is having volume attached to it that is stateful container, which is not having volume attached to it that is stateless.
   
8. what is git fetch ?
   - only downloads latest changes into the local repo. it downloads fresh changes that other developers have pushed to the remote repo.
     it does not merge latest changes to your working dir.
     
9. if my origin origin 2 commits beyond the master how to do that?

10. explain about the Dockerfile structure ?
    FROM centos
    RUN yum install telnet -y && useradd anil  => to run the command inside the container
    ENV MYCOURSE=DevOps  => to export the env variables
    ADD mytarfile.tar /root/  => untar and copy the file
    COPY mytarfile.tr /root/ => only copy the file
    USER anil  => run an image with the user anil
    EXPOSE 80  => to expose the container on port 80 
    WORKDIR /root/mydir  => to specify the working dir in container
    ENTRYPOINT ["/bin/bash", "/tmp/script1.sh"]  
    CMD ["/bin/bash", "/tmp/script1.sh"]
    
11. what is the difference between CMD and ENTRYPOINT ?
    CMD
      vi Dockerfile
      FROM centos
      CMD [ "yum", "-y", "install", "git"
      $ docker build -t demobox .
      $ docker run demobox yum -y install httpd
      - CMD command can override git with httpd while executing container
      CMD [ "yum", "-y", "install", "httpd" ]
      CMD [ "echo", "Anil" ]
      - only last command will get executed, it will print only Anil i wil not install httpd 
    
    ENTRYPOINT
      vi Dockerfile
      FROM centos
      CMD [ "yum", "-y", "install", "git"
      $ docker build -t demobox .
      $ docker run demobox yum -y install httpd
      - ENTRYPOINT command won't override i will append to the existing command
        i will install both git and httpd.
      ENTRYPOINT [ "yum", "-y", "install", "httpd" ]
      ENTRYPOINT [ "echo", "Anil" ]
      - only last instruction gets executed
      ENTRYPOINT [ "yum", "-y", "install", "httpd" ]
      ENTRYPOINT [ "echo", "Anil" ]
      $ docker run --entrypoint useradd demobox anil
      it will update the entrypoint whatever has been mentioned in the entrypoint that won't be executed.
      
    12. explain about the docker compose ?
    Docker Compose is a tool that was developed to help define and share multi-container applications. 
    docker compose up -d
    
    services:
  app:
    image: node:18-alpine
    command: sh -c "yarn install && yarn run dev"
    ports:
      - 3000:3000
    working_dir: /app
    volumes:
      - ./:/app
    environment:
      MYSQL_HOST: mysql
      MYSQL_USER: root
      MYSQL_PASSWORD: secret
      MYSQL_DB: todos

  mysql:
    image: mysql:8.0
    volumes:
      - todo-mysql-data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: secret
      MYSQL_DATABASE: todos

volumes:
  todo-mysql-data:
  
13. what are the different types of jenkins jobs ?
    Maven job, freestyle job, pipeline job.
    
14. what is blue ocean in jenkins ?
    - Blue Ocean is a new user experience for Jenkins based on a personalizable, modern design that allows users to graphically create, 
      visualize and diagnose Continuous Delivery (CD) Pipelines 
    - Alternative options for Pipeline visualization, such as the Pipeline: Stage View and Pipeline Graph View 
    
15. what is poll SCM in Jenkins ?
    - "Poll SCM" polls the SCM periodically for checking if any changes/ new commits were made and shall build the project 
       if any new commits were pushed since the last build.
    - whereas the "build"  shall build the project periodically irrespective to whether or not any changes were made.
    
16. what is multibranch jenkins job?
    
17. what is the lifecycle of multibranch jenkins job?
18. how can you store the credentials in Jenkins?
    Manage jenkins -> configure credentials -> jenkins -> global tool credentials
19. what is the default jenkins dir ?
20. what is the difference between variables and env variables?
21. how to check the syntax error in terraform?
    $ terraform validate 
    
22. How the two containers will communicate each other ?
    create the network and attach same network to two containers
    
23. what is bridge network and how many networks are there in docker ?
    bridge network is the default network in the docker.
    - Dockerhost will be having different subnet and container will be having differenet subnet, whenever you create a container
        a bridge network will automatically create it makes the communication between dockerhost and container, bridge network can be called as
        docker0.
     Host network:- when you create a container it will directly bind to the host network like, whatever dockerhost is having ip address same rang
        of ip address range will get to container. whoever access to host can have access to container as well. this is having some security concerns.
    
24. infrastructure as a service lifecycle.
25. what is the use of main.tf ?
    if we want to call any particular module then we can define in main.tf
    
26. how to view the more information about pod.
    $ kubectl describe pod nginx
    
27. how can you do the kubernetes setup.
28. what is telnet and why to use it ?
    if we can want login to the instance then we should use telnet
    
29. why do you use netstat command ?
    to check the ports
30. what could be the reasons if container is not running up?

31. how to share the information between two tightly coupled containers ?
   using bind mount
   
   $ docker run -it --name container1 nginx /bin/bash
     when you run the container it will creat the docker volume on the host machine under the /var/lib/docker with the name called random has name
     when you delete the container docker volume also will be wiped off.
     
   ananymous volumes
   $ docker run -it --name container1 -v /data01 nginx /bin/bash -> 
     volume will not be having any name, you will get one alpha numeric docker volume name
     /var/lib/docker/volumes/<apha-numeric>/_data/filename
     when you do docker inspect <apha-numeric>, it will not show on which continer i has been mapped
     
  Named volumes
  $ docker volume create volume1
  $ docker run -it --name container1 -v volume1:/data01 nginx /bin/bash
  volume will be mounte to the dir called /data01 
  the data will be available Docker host under /var/lib/docker/volumes/volume1/_data/filename
  
  Bind volumes
  $ docker run -it --name container1 -v /opt/data:/data01 nginx /bin/bash
  docker volume will not be created on docker dir called /var/lib/docker/volumes
  /opt/data dir will be created on docker host and it can be shared with multiple containers like NFS
  
4th interview - OpenText
1. write the Dockerfile and explain each innstruction ?
   
2. Explain about the docker networks
3. What is Docker compose, why do we use this ?
4. what is multistage build and why do we use this?
5. what are the security parameters have to take while creating docker imagge ?
6. which instructions will not be creating layers on Dockerfile.
7. how can you login to the docker container?
8. write the declarative pipeline syntax?
9. How to take the backup of the jenkins?
10. what is the default jenkins directory ?
    /var/lib/jenkins
11. how can you do the continuoes integration with jenkins to github?
12. Write the terraform script to create the instance
13. what is difference between terraform and ansible ?
14. if the state file has been delete, if am going to do terraform apply it is going to create resources ?
15. what is terraform import and why to use that ?
16. write an ansible playbook to install httpd server
17. what are the ansile handlers
18. if one task is not working how can you skip that and go to next task ?
19. what are the ansible tags ?
20. why do you use ansible galaxy and ansile tower?
21. explain about kubernetes architecture and master and slave components ?
22. what are kubernetes taints and tolerations ?

23. what are the pod affinity and node affinity and what is the difference between selectors?
    NodeSelector:- nodeSelector is the simplest recommended form of node selection constraint
    - You can add the nodeSelector field to your Pod specification and specify the node labels you want
    - the target node to have. Kubernetes only schedules the Pod onto nodes that have each of the labels you specify.
    
    Node Affinity:-
    - Node Affinity is conceptually similar to nodeselector. it will be having more expressive way and operators.
      requiredDuringSchedulingIgnoredDuringExecution:- while scheduling the pod, pod should have same label otherwise it will sit on the pending state.
      IgnoredDuringExecution means that if the node labels change after Kubernetes schedules the Pod, the Pod continues to run.
      operators:- 
        in - it contains
        notin -  it does not contains
        Lt -  less than
        Gt -  greater than
        exist - it is having label
        doesNotExist - it does not having label
        
      preferredDuringSchedulingIgnoredDuringExecution: The scheduler tries to find a node that meets the rule. 
      If a matching node is not available, the scheduler still schedules the Pod.
    
    
24. whare are the services in kubernetes can you explain each of them ?

            apiVersion: v1
            kind: Service
            metadata:
            name: hello-world
            spec:
            type: NodePort
            selector:
            app: hello-world
            ports:
            - protocol: TCP
            port: 8080
            targetPort: 80
            nodePort: 30036
     Services allow your applications to receive traffic.
     Although each Pod has a unique IP address, those IPs are not exposed outside the cluster without a Service.
     The set of Pods targeted by a Service is usually determined by a label selector
     (see below for why you might want a Service without including a selector in the spec).
     Port:- exposes the Kubernetes service on the specified port within the cluster. 
         Other pods within the cluster can communicate with this server on the specified port.
         
     TargetPort:- is the port on which the service will send requests to, that your pod will be listening on. 
             Your application in the container will need to be listening on this port also.
             
     NodePort:- exposes a service externally to the cluster by means of the target nodes IP address and the NodePort. 
                 external traffic has access to fixed port on each worker node (30000 - 32767).
                 Nodeport services are not secure, you are basically opening the port to directly talk to service on each worker node
                 exter clients basically have access to the worker nodes directly.
                 
    LoadBalancer:- whenever we create loadbalancer service nodeport and clusterip services are creatly automatically, which loadbalancer
                   route the traffic to.
                   This provides an externally-accessible IP address that sends traffic to the correct port on your cluster nodes,
                   provided your cluster runs in a supported environment and is configured with the correct cloud load balancer provider package.
                   
                   $ kubectl expose deployment example --port=8765 --target-port=9376 \
        --name=example-service --type=LoadBalancer            
    $ kubectl get endpoints  => to check which pods are associated with the service
    
25. what is ingress why do we need to use that?
    - Kubernetes ingress resource is responsible for storing DNS routing rules in the cluster.
    - Ingress exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. 
    - Traffic routing is controlled by rules defined on the Ingress resource.
    Igress controlller
    - Accept traffic from outside the Kubernetes platform, and load balance it to pods (containers) running inside the platform
      - Monitor the pods running in Kubernetes and automatically update the load‑balancing rules when pods are added or removed from a service
    
26. what are the security paramameters for creating pod ?
27. what is service account in kubernetes ?
28. how do you implement RBAC ?
29. What is liveness and readiness probes and why do we use them ?
    Readiness Probe
    - Readiness probes determine whether or not a container is ready to serve requests. 
    - If the readiness probe returns a failed state, then Kubernetes removes the IP address for the container from the endpoints of all Services.
  
   Livenessprobe
   - Liveness probes determine whether or not an application running in a container is in a healthy state. 
   - If the liveness probe detects an unhealthy state, then Kubernetes kills the container and tries to redeploy it.
   
30. what is default kubernetes network ?
31. what is sidecar deployment ?
32. what is the daemonset ?
33. what is the difference betweeen SG and NACL
34. what are the different types of instances ?
35. what is null resources in terraform ?
